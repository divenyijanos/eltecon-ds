# Data Science (aka Regional economics)

The aim of the course is to provide a detailed introduction into the modern data science. Building upon basic knowledge in statistics, real data and actual business applications we cover the tools that are elemental in our day-to-day work as data scientists. The course is practice-oriented: students will work on their own data science projects throughout the course where they can apply the methods they learn.

The course materials can be accessed in the [course's GitHub page](https://github.com/divenyijanos/eltecon-ds).

# Format

The course consists of 13 weekly sessions of 2x90 minutes. Each session is going to be on-line (via Zoom), and include a shorter theoretical part and a longer practice-oriented part. The sessions are going to be held by an instructor and a co-instructor to better assist students with individual problems.

# Instructors

András Bérczi, János Divényi, Zsuzsa Holler, Gábor Kocsis, Tamás Koncz and Péter Lukács - members of the data science team of [Emarsys](https://www.emarsys.com/)

Contact: eltecon.ds@gmail.com

# Prerequisite

The course expects basic knowledge of the programming language `R` and the corresponding application `RStudio`. To refresh this knowledge, we collected supplementary materials into the "prerequisite" folder. This knowledge is necessary to successfully complete the course.

First, install [R](https://cran.r-project.org/) and [RStudio](https://www.rstudio.com/products/rstudio/download/) on your local machine. There are 4 topics in the prerequisite folder: R introduction, functions, data.table (for data manipulation), ggplot (for data visualization). Each topic contains a description, some sample exercises and references for further studies. The sample exercises show the level we expect throughout the course. To ensure that we are on the same page, we are going to spend some time on refreshing this knowledge in the first few weeks.

You can get the material by clicking on the button `Clone or download` and chosing the option `Download ZIP`. After extracting, you can browse the files. Each file has two versions: you can open the `html` files in your browser and view them, or you can open the `.Rmd` files in Rstudio and interact with the material (e.g. run code chunks).

# Evaluation

The final grade consists of two parts: weekly homeworks (50%) and the final project (50%). The students work on the tasks in pairs. The homeworks aim to help the final project, and each homework is going to be presented by some pairs at the beginning of the sessions. The final project is to be presented in a separate session, held on the 16th of December.

# Useful materials

- James - Witten - Hastie - Tibshirani: [An Introduction to Statistical Learning](http://faculty.marshall.usc.edu/gareth-james/ISL/)
- Grolemund - Hadley: [R for Data Science](https://r4ds.had.co.nz/)
- Gentzkow - Shapiro: [Code and Data for the Social Sciences: A Practitioner's Guide](https://web.stanford.edu/~gentzkow/research/CodeAndData.pdf)
- Emarsys Craftlab blog: [data section](https://blog.craftlab.hu/tagged/emarsys-data)

# Schedule

1. **9 September** Introduction: R and RStudio (project setup, directory structure, relative paths), data types in R (vectors, factors, lists, data frames), R packages, functions, loops, error handling. (*Gábor Kocsis*)
2. **16 September**  Data manipulation with data.table. Exploratory data analysis and data cleaning. (*Gábor Kocsis*)
3. **23 September**  Data visualization with ggplot2: how to make plots. (*Péter Lukács*)
4. **30 September** Data visualization principles: how to make plots that make sense. (*Péter Lukács*)
5. **7 October** Effect measurement with experiments (RCT, AB test): issues in practice.  (*András Bérczi*)
6. **14 October** Measuring uncertainty, simulation methods: Monte-Carlo. (*András Bérczi*)
7. **21 October** Simulation methods: bootstrap. (*Tamás Koncz*)
8. **28 October** Fall Break
9. **4 November** Machine learning introduction. Supervised learning basics: regression and binary prediction. Prediction versus causality. (*Tamás Koncz*)
10. **11 November** Model Selection. Overfitting and prediction accuracy. Training, test error and cross-validation. (*Zsuzsa Holler*)
11. **18 November** Regularisation. Lasso and Ridge Regression. (*Zsuzsa Holler*)
12. **25 November** Supervised learning beyond linearity: decision tree. (*János Divényi*)
13. **2 December** Unsupervised learning: clustering (K-means), dimensionality reduction (PCA). (*János Divényi*)
14. **9 December** Project consultation (*with all instructors*)
